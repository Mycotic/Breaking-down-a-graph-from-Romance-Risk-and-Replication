{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2015, the metastudy \"Romance, Risk, and Replication\" was published. It reviewed a set of published studies on romantic priming, and did some replication studies to compare the original studies with. The metastudy found that the smaller the standard error of a published study, the closer its effect size was to $0$, despite most of the published studies having $95\\%$ confidence that romantic priming was effective. I'm going to go over what all these statistics mean, and what exactly this graph is showing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.ctfassets.net/cnu0m8re1exe/2tRRxZNHt3bPnzfNJiYjTq/662d9ff053e3e5440e38d756b5b63af3/funnel_shanks1.png?w=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the variables\n",
    "\n",
    "#### Standard error\n",
    "Given a population, the standard error $E$ is the standard deviation of the means of potential samples of size $n$.\n",
    "The formula for this is \n",
    "\n",
    "$E = \\frac{\\sigma}{\\sqrt{n}}$ ,\n",
    "\n",
    "where $\\sigma$ is the standard deviation of the population.\n",
    "Often a sample is collected, and the standard error of the population is predicted using the sample's standard deviation in place of the population's (these are generally close). This can then be used to estimate the population's true mean is. \n",
    "\n",
    "#### Effect size (using cohen's d)\n",
    "$d = \\frac{m_1-m_2}{s}$\n",
    "where $m_1$ is the observed mean, $m_2$ is the null hypothesis mean, and s is the standard deviation of the sample.\n",
    "Cohen's D is a measure of the difference between your sample mean and the null hypothesis mean put in the context of the spread of your sample. \n",
    "\n",
    "Note that the effect size *does not* measure the significance of the difference between your sample and the null mean. This is because effect size doesn't take into account how much data is collected. Even if your effect size is small, your sample may be significantly different from the null mean if you collect enough of it. In fact, if you look at the basic formula for the significance of the difference between a sample mean and a null mean,\n",
    "\n",
    "$Z = \\frac{m_1-m_2}{s / \\sqrt{n}}$,\n",
    "\n",
    "you can see that effect size is an element of the formula (by taking $\\frac{1}{\\sqrt{n}}$ out of the denominator):\n",
    "\n",
    "$Z = \\frac{m_1-m_2}{s} \\sqrt{n}$  &nbsp; or &nbsp; $Z = d \\sqrt{n}$.\n",
    "\n",
    "Looking at the effect size from this perspective, the effect size indicates how significant the size of your sample is.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.ctfassets.net/cnu0m8re1exe/2tRRxZNHt3bPnzfNJiYjTq/662d9ff053e3e5440e38d756b5b63af3/funnel_shanks1.png?w=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it that, as the standard error of published studies goes down, the studies' effect size approaches $0$?\n",
    "\n",
    "Given that the standard deviation of each study should be roughly the same, we know that studies with lower standard error will be those that have a larger sample size. We also know that the standard deviation of sample means gets smaller and smaller as the sample size increases. Given that standard error goes down as sample size increases, and that sample means approach population means as sample size increases, we know that samples with lower standard error should be closer to their population mean.\n",
    "\n",
    "So the conclusion is, the romantic priming population has the same mean as the total population. However, all the published studies stated the opposite was true, mostly with $95\\%$ accuracy. Why is this happening? One answer is p-hacking. P-hacking is the process of increasing your z-score so that it's greater than the breakpoint for your $95\\%$ confidence interval. This can be done by eliminating data that looks like outliers or changing the metric used to evaluate data. \n",
    "\n",
    "Another possibility is that there were studies that didn't have significantly different data just weren't published. However, studies that do have statistically significant results probably have a lot more value. Maybe selecting for statistically significant studies and then confirming accuracy with replication or with metastudies is in fact a good process? It's hard to say what the best method for handling this kind of error is.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent:\n",
    "How is the graph able to plot where studies have to be to be statistically significant in terms of standard error and Cohen's d? If we look at the formula for statistical significance, $z=d\\sqrt{n}$ , it's put in terms of cohen's d and sample size. sqrt(n) isn't linearly related to the standard error because standard error takes two variables, sample size and standard deviation... except that standard deviation should actually be constant! Let's see if the math checks out.<br/>\n",
    "Givens:<br/>\n",
    "$e=\\frac{s}{\\sqrt{n}}$<br/>\n",
    "$Z=d\\sqrt{n}$<br/>\n",
    "\n",
    "Rephrasing the significance in terms of Cohen's d and standard error (and the constant standard deviation) we get\n",
    "\n",
    "$Z=\\frac{ds}{e}$.<br/>\n",
    "\n",
    "Now if we want to draw the line beyond which studies will have a $95%$ confidence (it's one-tail so $z=1.645$) that their sample mean is greater than the population mean, we can just plot \n",
    "\n",
    "$1.645 = \\frac{ds}{e}$.\n",
    "\n",
    "(Turns out we do need to know the standard deviation of at least one sample - I thought we could calculate it based on a given study but after a lot of thought that could produce wildly misleading results despite giving fine ones in practice.) \n",
    "\n",
    "What we can do is calculate the standard deviation based on the line that was actually plotted. \n",
    "\n",
    "![](https://raw.githubusercontent.com/Mycotic/Breaking-down-a-graph-from-Romance-Risk-and-Replication/master/funnel_shanks1%20drawn.png)\n",
    "\n",
    "Let's plug the info from the point on the $95$% confidence line where Cohen's d is $.5$ and the standard error is $.24$:\n",
    "\n",
    "$1.645 = \\frac{.5s}{.24}$\n",
    "\n",
    "or $s=.79$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source(s) and further reading\n",
    "\"Romance, Risk, and Replication\":\n",
    "\n",
    "https://pubmed.ncbi.nlm.nih.gov/26501730/\n",
    "\n",
    "Article about the paper (the paper itself is behind a paywall):\n",
    "\n",
    "https://www.discovermagazine.com/mind/reproducibility-crisis-the-plot-thickens\n",
    "\n",
    "More misleading statistical drama:\n",
    "\n",
    "https://io9.gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800\n",
    "\n",
    "(and thanks to learn.co sorry most of you can't use this =)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
